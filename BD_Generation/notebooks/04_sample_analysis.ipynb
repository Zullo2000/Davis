{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 — Sample Analysis\n",
    "\n",
    "Generate samples from a trained checkpoint, visualize them, and compute evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure BD_Generation is importable\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from bd_gen.data.vocab import VocabConfig, RPLAN_VOCAB_CONFIG, NODE_PAD_IDX, NODE_TYPES, EDGE_TYPES\n",
    "from bd_gen.data.tokenizer import detokenize\n",
    "from bd_gen.data.dataset import BubbleDiagramDataset\n",
    "from bd_gen.model.denoiser import BDDenoiser\n",
    "from bd_gen.diffusion.noise_schedule import get_noise\n",
    "from bd_gen.diffusion.sampling import sample\n",
    "from bd_gen.utils.checkpoint import load_checkpoint\n",
    "from bd_gen.eval.validity import check_validity, check_validity_batch\n",
    "from bd_gen.eval.metrics import validity_rate, diversity, novelty, distribution_match\n",
    "from bd_gen.viz.graph_viz import draw_bubble_diagram, draw_bubble_diagram_grid\n",
    "\n",
    "vc = RPLAN_VOCAB_CONFIG\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THIS PATH to your trained checkpoint\n",
    "CHECKPOINT_PATH = PROJECT_ROOT / \"outputs\" / \"TIMESTAMP\" / \"checkpoints\" / \"checkpoint_final.pt\"\n",
    "\n",
    "# Model config (must match training config)\n",
    "model = BDDenoiser(\n",
    "    d_model=128, n_layers=4, n_heads=4,\n",
    "    vocab_config=vc, dropout=0.0,\n",
    ").to(device)\n",
    "\n",
    "load_checkpoint(CHECKPOINT_PATH, model, device=device)\n",
    "model.eval()\n",
    "print(f\"Loaded checkpoint: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "noise_cfg = OmegaConf.create({\"type\": \"linear\", \"sigma_min\": 0.0, \"sigma_max\": 10.0})\n",
    "noise_schedule = get_noise(noise_cfg).to(device)\n",
    "\n",
    "# Load training set for num_rooms distribution\n",
    "train_ds = BubbleDiagramDataset(\n",
    "    mat_path=PROJECT_ROOT / \"data\" / \"data.mat\",\n",
    "    cache_path=PROJECT_ROOT / \"data_cache\" / \"graph2plan_nmax8.pt\",\n",
    "    vocab_config=vc, split=\"train\", seed=42,\n",
    ")\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = sample(\n",
    "        model=model, noise_schedule=noise_schedule, vocab_config=vc,\n",
    "        batch_size=NUM_SAMPLES, num_steps=100, temperature=0.0,\n",
    "        num_rooms_distribution=train_ds.num_rooms_distribution,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "print(f\"Generated {tokens.shape[0]} samples, shape: {tokens.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct pad masks and detokenize\n",
    "graph_dicts = []\n",
    "pad_masks = torch.zeros_like(tokens, dtype=torch.bool)\n",
    "\n",
    "for i in range(tokens.size(0)):\n",
    "    node_toks = tokens[i, :vc.n_max]\n",
    "    nr = int((node_toks != NODE_PAD_IDX).sum().item())\n",
    "    nr = max(1, min(nr, vc.n_max))\n",
    "    pad_masks[i] = vc.compute_pad_mask(nr)\n",
    "    try:\n",
    "        gd = detokenize(tokens[i], pad_masks[i], vc)\n",
    "        graph_dicts.append(gd)\n",
    "    except ValueError:\n",
    "        graph_dicts.append({\"num_rooms\": 0, \"node_types\": [], \"edge_triples\": []})\n",
    "\n",
    "# Visualize first 16\n",
    "viz_dicts = [g for g in graph_dicts[:16] if g[\"num_rooms\"] > 0]\n",
    "fig = draw_bubble_diagram_grid(viz_dicts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = check_validity_batch(tokens, pad_masks, vc)\n",
    "\n",
    "v_rate = validity_rate(results)\n",
    "connected_rate = sum(1 for r in results if r[\"connected\"]) / len(results)\n",
    "valid_types_rate = sum(1 for r in results if r[\"valid_types\"]) / len(results)\n",
    "no_mask_rate = sum(1 for r in results if r[\"no_mask_tokens\"]) / len(results)\n",
    "\n",
    "print(f\"Validity rate:    {v_rate:.1%}\")\n",
    "print(f\"Connected rate:   {connected_rate:.1%}\")\n",
    "print(f\"Valid types rate: {valid_types_rate:.1%}\")\n",
    "print(f\"No MASK rate:     {no_mask_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detokenize training set\n",
    "train_dicts = []\n",
    "for idx in range(min(len(train_ds), 5000)):  # Subsample for speed\n",
    "    item = train_ds[idx]\n",
    "    try:\n",
    "        gd = detokenize(item[\"tokens\"], item[\"pad_mask\"], vc)\n",
    "        train_dicts.append(gd)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "div = diversity(graph_dicts)\n",
    "nov = novelty(graph_dicts, train_dicts)\n",
    "dm = distribution_match(graph_dicts, train_dicts)\n",
    "\n",
    "print(f\"Diversity: {div:.3f}\")\n",
    "print(f\"Novelty:   {nov:.3f}\")\n",
    "print(f\"KL divergence — nodes: {dm['node_kl']:.4f}, edges: {dm['edge_kl']:.4f}, rooms: {dm['num_rooms_kl']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Node type distributions\n",
    "sample_nodes = Counter(nt for g in graph_dicts for nt in g[\"node_types\"])\n",
    "train_nodes = Counter(nt for g in train_dicts for nt in g[\"node_types\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Node types\n",
    "x = range(len(NODE_TYPES))\n",
    "s_total = max(sum(sample_nodes.values()), 1)\n",
    "t_total = max(sum(train_nodes.values()), 1)\n",
    "axes[0].bar([i - 0.2 for i in x], [sample_nodes.get(i, 0) / s_total for i in x], 0.4, label=\"Generated\")\n",
    "axes[0].bar([i + 0.2 for i in x], [train_nodes.get(i, 0) / t_total for i in x], 0.4, label=\"Training\")\n",
    "axes[0].set_xticks(list(x))\n",
    "axes[0].set_xticklabels([n[:4] for n in NODE_TYPES], rotation=45, ha=\"right\")\n",
    "axes[0].set_title(\"Node Type Distribution\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Edge types\n",
    "sample_edges = Counter(rel for g in graph_dicts for _, _, rel in g[\"edge_triples\"])\n",
    "train_edges = Counter(rel for g in train_dicts for _, _, rel in g[\"edge_triples\"])\n",
    "x = range(len(EDGE_TYPES))\n",
    "s_total = max(sum(sample_edges.values()), 1)\n",
    "t_total = max(sum(train_edges.values()), 1)\n",
    "axes[1].bar([i - 0.2 for i in x], [sample_edges.get(i, 0) / s_total for i in x], 0.4, label=\"Generated\")\n",
    "axes[1].bar([i + 0.2 for i in x], [train_edges.get(i, 0) / t_total for i in x], 0.4, label=\"Training\")\n",
    "axes[1].set_xticks(list(x))\n",
    "axes[1].set_xticklabels([e[:6] for e in EDGE_TYPES], rotation=45, ha=\"right\")\n",
    "axes[1].set_title(\"Edge Type Distribution\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Num rooms\n",
    "sample_rooms = Counter(g[\"num_rooms\"] for g in graph_dicts)\n",
    "train_rooms = Counter(g[\"num_rooms\"] for g in train_dicts)\n",
    "x = range(1, vc.n_max + 1)\n",
    "s_total = max(sum(sample_rooms.values()), 1)\n",
    "t_total = max(sum(train_rooms.values()), 1)\n",
    "axes[2].bar([i - 0.2 for i in x], [sample_rooms.get(i, 0) / s_total for i in x], 0.4, label=\"Generated\")\n",
    "axes[2].bar([i + 0.2 for i in x], [train_rooms.get(i, 0) / t_total for i in x], 0.4, label=\"Training\")\n",
    "axes[2].set_xticks(list(x))\n",
    "axes[2].set_title(\"Num Rooms Distribution\")\n",
    "axes[2].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
